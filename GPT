ls /dev/video*

sudo apt-get install fswebcam

fswebcam -r 1280x720 --no-banner /path/to/save/image.jpg

crontab -e

0 * * * * fswebcam -r 1280x720 --no-banner /path/to/save/image_$(date +\%Y\%m\%d_\%H\%M\%S).jpg

本地
scp pi@<樹莓派 IP 地址>:/path/to/shared/image.jpg C:\local\path\to\save\



orange to SQL 下載window
https://orangedatamining.com/blog/how-to-enable-sql-widget-in-orange/
https://pypi.org/project/pymssql/#files <-載這個
試試看orange的add-one
https://orangedatamining.com/download/
https://pypi.org/project/Orange3/3.7.1/#files

國人的OCR，下載試試
https://github.com/PaddlePaddle/PaddleOCR?tab=readme-ov-file #線上版試試，自己拍照
https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/windows-pip.html
https://www.paddlepaddle.org.cn/whl/windows/mkl/avx/stable.html
https://www.lfd.uci.edu/~gohlke/pythonlibs/#shapely

def load_model(weights, device):
    # Load model
    model = attempt_load(weights, map_location=device)  # load FP32 model
    stride = int(model.stride.max())  # model stride
    imgsz = check_img_size(imgsz, s=stride)  # check img_size

    if half:
        model.half()  # to FP16

    return model, imgsz, stride

def detect(model, img, names, colors, imgsz, device, opt):
    # Process the image
    img = torch.from_numpy(img).to(device)
    img = img.half() if half else img.float()  # uint8 to fp16/32
    img /= 255.0  # 0 - 255 to 0.0 - 1.0
    if img.ndimension() == 3:
        img = img.unsqueeze(0)

    with torch.no_grad():   # Calculating gradients would cause a GPU memory leak
        pred = model(img, augment=opt.augment)[0]

    # Apply NMS
    pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)

    # Process detections
    for i, det in enumerate(pred):  # detections per image
        p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)
        p = Path(p)  # to Path

        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
        if len(det):
            # Rescale boxes from img_size to im0 size
            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

            # Print results
            for c in det[:, -1].unique():
                n = (det[:, -1] == c).sum()  # detections per class
                s += f"{n} {names[int(c)]}{'s' * (n > 1)}、"  # add to string

            # Write results
            for *xyxy, conf, cls in reversed(det):
                label = f'{names[int(cls)]} {conf:.2f}'
                plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)

# Load the model only once
model, imgsz, stride = load_model(opt.weights, device)

# Now, you can continuously process images
for path, img, im0s, vid_cap in dataset:
    detect(model, img, names, colors, imgsz, device, opt)
